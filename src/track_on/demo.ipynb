{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as Tr\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Download checkpoint ===\n",
    "checkpoint_path = \"./checkpoints/track_on_checkpoint.pt\"\n",
    "\n",
    "# !wget -O ./checkpoints/track_on_checkpoint.pt \"https://huggingface.co/gaydemir/track_on/resolve/main/track_on_checkpoint.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper functions ===\n",
    "def read_video(video_path):\n",
    "    reader = imageio.get_reader(video_path)\n",
    "    frames = []\n",
    "    for i, im in enumerate(reader):\n",
    "        frames.append(np.array(im))\n",
    "    video = np.stack(frames)\n",
    "    video = torch.from_numpy(video).permute(0, 3, 1, 2).float()  # (T, 3, 720, 1920)\n",
    "    \n",
    "    print(f\"{video.shape[0]} frames in video\")\n",
    "    \n",
    "    plt.imshow(video[0].permute(1, 2, 0).long())\n",
    "    \n",
    "    return video\n",
    "    \n",
    "def write_gif(png_dir, out_dir):\n",
    "    images = []\n",
    "    \n",
    "    sorted_files = sorted([f for f in os.listdir(png_dir) if f.endswith('.png')], key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    for z, file_name in enumerate(sorted_files):    \n",
    "        file_path = os.path.join(png_dir, file_name)\n",
    "        images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(out_dir, images, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Read video ====\n",
    "video_path = \"media/messi.mp4\"\n",
    "video = read_video(video_path)  # (T, 3, H, W)\n",
    "# === === ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Set queries manually ====\n",
    "queries = []\n",
    "for x in range(1140, 1200, 20):\n",
    "    for y in range(300, 350, 50):\n",
    "        queries.append([x, y])\n",
    "\n",
    "N = len(queries)\n",
    "\n",
    "distinct_colors = plt.cm.tab20(np.linspace(0, 1, N))\n",
    "hex_colors = ['#%02x%02x%02x' % (int(r*255), int(g*255), int(b*255)) for r, g, b, _ in distinct_colors]\n",
    "\n",
    "queries = torch.tensor(queries)\n",
    "\n",
    "plt.imshow(video[0].permute(1, 2, 0).long())\n",
    "for i, q in enumerate(queries):\n",
    "    plt.scatter(q[0], q[1], s=20, c=hex_colors[i])\n",
    "\n",
    "# === === ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Set Model Arguments ===\n",
    "from utils.train_utils import restart_from_checkpoint_not_dist\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.input_size = [384, 512]\n",
    "\n",
    "        self.N = 384\n",
    "        self.T = 18\n",
    "        self.stride = 4\n",
    "        self.transformer_embedding_dim = 256\n",
    "        self.cnn_corr = False\n",
    "        self.linear_visibility = False\n",
    "        \n",
    "        self.num_layers = 3\n",
    "        self.num_layers_offset_head = 3\n",
    "        \n",
    "        self.num_layers_rerank = 3\n",
    "        self.num_layers_rerank_fusion = 1\n",
    "        self.top_k_regions = 16\n",
    "\n",
    "        self.num_layers_spatial_writer = 3\n",
    "        self.num_layers_spatial_self = 1\n",
    "        self.num_layers_spatial_cross = 1\n",
    "        \n",
    "        self.memory_size = 12\n",
    "        self.val_memory_size = 96\n",
    "        self.val_vis_delta = 0.9\n",
    "        self.random_memory_mask_drop = 0\n",
    "\n",
    "        self.lambda_point = 5.0\n",
    "        self.lambda_vis = 1.0\n",
    "        self.lambda_offset = 1.0\n",
    "        self.lambda_uncertainty = 1.0\n",
    "        self.lambda_top_k = 1.0\n",
    "        \n",
    "        self.epoch_num = 4\n",
    "        self.lr = 1e-3\n",
    "        self.wd = 1e-4\n",
    "        self.bs = 1\n",
    "        self.gradient_acc_steps = 1\n",
    "\n",
    "        self.validation = False\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.seed = 1234\n",
    "        self.loss_after_query = True\n",
    "\n",
    "        self.gpus = torch.cuda.device_count()\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: Frame inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.track_on_ff import TrackOnFF    # Frame Inputs\n",
    "\n",
    "model = TrackOnFF(args)\n",
    "restart_from_checkpoint_not_dist(args, run_variables={}, model=model)\n",
    "\n",
    "model.cuda().eval()\n",
    "model.set_memory_size(args.val_memory_size, args.val_memory_size)\n",
    "model.visibility_treshold = args.val_vis_delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = video.shape[0]\n",
    "N = queries.shape[0]\n",
    "\n",
    "png_folder = \"./out/messi\"\n",
    "Path(png_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "vis_all = []\n",
    "point_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(T):\n",
    "    \n",
    "        # === For the first frame, initialize the queries and memories ===\n",
    "        if t == 0:\n",
    "            model.init_queries_and_memory(queries.cuda(), video[t].unsqueeze(0).cuda())\n",
    "        # === === ===\n",
    "    \n",
    "        # === Model forward, for each frame ===\n",
    "        \n",
    "        point, vis = model.ff_forward(video[t].unsqueeze(0).cuda())\n",
    "        # === === ===\n",
    "    \n",
    "        # === Save the predictions frame-by-frame ===\n",
    "        vis_all.append(vis)\n",
    "        point_all.append(point)\n",
    "        \n",
    "        plt.imshow(video[t].permute(1, 2, 0).long())\n",
    "        for n in range(N):\n",
    "            if vis[n]:\n",
    "                plt.scatter(point[n, 0].cpu(), point[n, 1].cpu(), c=hex_colors[n], s=20)\n",
    "    \n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(os.path.join(png_folder, f\"{t}.png\"), bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        # === === ===\n",
    "\n",
    "write_gif(png_folder, os.path.join(png_folder, \"out.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Video inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.track_on import TrackOn    # Video Inputs\n",
    "\n",
    "model = TrackOn(args)\n",
    "restart_from_checkpoint_not_dist(args, run_variables={}, model=model)\n",
    "\n",
    "model.cuda().eval()\n",
    "model.set_memory_size(args.val_memory_size, args.val_memory_size)\n",
    "model.visibility_treshold = args.val_vis_delta\n",
    "\n",
    "\n",
    "T = video.shape[0]\n",
    "N = queries.shape[0]\n",
    "\n",
    "video_tmp = video.unsqueeze(0).cuda()                                                # (1, T, 3, H, W)\n",
    "queries_tmp = torch.cat([torch.zeros(N, 1, device=queries.device), queries], dim=1)  # (N, 3), to (t, x, y) format, with all t = 0\n",
    "queries_tmp = queries_tmp.unsqueeze(0).cuda()                                        # (1, N, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.inference(video_tmp, queries_tmp)\n",
    "    \n",
    "vis_all = out[\"visibility\"]   # (1, T, N)\n",
    "point_all = out[\"points\"]     # (1, T, N, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save the predictions by looping them all ===\n",
    "png_folder = \"./out/messi\"\n",
    "Path(png_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "for t in range(T):\n",
    "    plt.imshow(video_tmp[0, t].permute(1, 2, 0).long().cpu())\n",
    "    for n in range(N):\n",
    "        if vis_all[0, t, n]:\n",
    "            plt.scatter(point_all[0, t, n, 0].cpu(), point_all[0, t, n, 1].cpu(), c=hex_colors[n], s=20)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(os.path.join(png_folder, f\"{t}.png\"), bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "write_gif(png_folder, os.path.join(png_folder, \"out_vi.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/root1/anaconda3/envs/trackon/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "正在加载模型...\n",
      "/home/root1/Corenetic/code/project/track_on/utils/train_utils.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
      "=> loaded 'model' from checkpoint with msg <All keys matched successfully>\n",
      "Model loaded on cuda\n",
      "模型加载完成！\n",
      "\n",
      "摄像头已打开\n",
      "无显示模式：追踪结果将输出到控制台\n",
      "按 Ctrl+C 退出追踪\n",
      "\n",
      "从命令行参数解析关键点: 320,240 100,100\n",
      "已解析 2 个关键点\n",
      "\n",
      "正在初始化追踪，关键点数量: 2\n",
      "追踪初始化完成！\n",
      "Frame 30: 2/2 points visible\n",
      "Frame 60: 2/2 points visible\n",
      "Frame 90: 2/2 points visible\n",
      "Frame 120: 2/2 points visible\n",
      "Frame 150: 2/2 points visible\n",
      "Frame 180: 2/2 points visible\n",
      "Frame 210: 2/2 points visible\n",
      "Frame 240: 2/2 points visible\n",
      "\n",
      "用户中断\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"track_with_camera.py\", line 354, in <module>\n",
      "    main()\n",
      "  File \"track_with_camera.py\", line 345, in main\n",
      "    cap.release()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python track_camera.py --checkpoint_path checkpoints/track_on_checkpoint.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
